{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2f8d576-41b5-4076-9618-cd82d82a11ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "# India Cotton Analysis - EDA Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fbae7d6-59c5-43b8-8acf-578670596bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "import unicodedata\n",
    "\n",
    "import sqlalchemy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "import re\n",
    "from ipywidgets import interact, IntSlider, fixed\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "from shapely.ops import unary_union\n",
    "from shapely import wkt\n",
    "from shapely.prepared import prep\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(29)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebbbde7-1c08-4831-9687-08fa46aece8f",
   "metadata": {},
   "source": [
    "### Load in Data\n",
    "- Geographic Data : [link](https://data.humdata.org/dataset/geoboundaries-admin-boundaries-for-india?force_layout=desktop)\n",
    "- Climate Data : [link](https://datacatalog.worldbank.org/search/dataset/0061895/India-Climatic-Data)\n",
    "- Cotton Prices : [link](https://fred.stlouisfed.org/series/PCOTTINDUSDM#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f7daf18-9b27-44ee-9ddb-9aa1efe0100b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Geographic Data\n",
    "path = './data/geographic_data/geoBoundaries-IND-ADM1_simplified.geojson'\n",
    "india_state_geos = gpd.read_file(path)\n",
    "india_state_geos.index.name = 'asdf_id'\n",
    "\n",
    "path = './data/geographic_data/geoBoundaries-IND-ADM2_simplified.geojson'\n",
    "india_admin_geos = gpd.read_file(path)\n",
    "india_admin_geos.index.name = 'asdf_id'\n",
    "\n",
    "### Climate Data\n",
    "path = './data/geographic_data/GeoQuery_India_ADM2_results.csv'\n",
    "climate_data = pd.read_csv(path).set_index('asdf_id')\n",
    "\n",
    "path = './data/agricultural_data/crop_yield.csv'\n",
    "crop_yields = pd.read_csv(path)\n",
    "\n",
    "### Cotton Prices\n",
    "path = './data/economic_data/cotton_prices_1990_2024.csv'\n",
    "cotton_prices = pd.read_csv(path)\n",
    "cotton_prices['DATE'] = pd.to_datetime(cotton_prices['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c18a5e28-75cf-4103-8243-bb3525c82f85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd_years = []\n",
    "\n",
    "for col in climate_data.columns:\n",
    "    try:\n",
    "        yr = int(col.split('.')[-2])\n",
    "        if (yr not in cd_years) & (yr < 2024):\n",
    "            cd_years.append(yr)\n",
    "    ### For named columns (e.g. 'Shape_Area')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c02d727-3fdc-4e96-afc9-40b05e5bea98",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a121a8-028e-4efe-b96a-eda79e38ddc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### `india_state_geos` \\& `india_admin_geos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e81a38d0-4999-4ae8-9a82-052684cf41f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_accents(input_str):\n",
    "    '''\n",
    "    Description\n",
    "    --------------------------------------------------\n",
    "    Removes diacritical marks (accents) from a given\n",
    "    string.\n",
    "    \n",
    "    Inputs\n",
    "    --------------------------------------------------\n",
    "    + input_str : str; the input string from which to\n",
    "      remove accents\n",
    "    \n",
    "    Outputs\n",
    "    --------------------------------------------------\n",
    "    + Returns a string with accents removed.\n",
    "    '''\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    return ''.join([c for c in nfkd_form if not unicodedata.combining(c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa7f0cc2-8f81-466a-b6f6-2d4afea5f105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### This ensures consistency between the state names in \n",
    "### crop_yields & india_state_geos\n",
    "india_state_geos['shapeName'] = india_state_geos['shapeName'].str.lower().apply(remove_accents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bf32bdd-218c-4575-b900-47f2115e3d4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def determine_state(polygon, state_gdf):\n",
    "    '''\n",
    "    Description\n",
    "    --------------------------------------------------\n",
    "    Determines the state in which a given polygon is \n",
    "    located by checking intersections with state \n",
    "    geometries.\n",
    "    \n",
    "    Inputs\n",
    "    --------------------------------------------------\n",
    "    + polygon : shapely.geometry.Polygon; the polygon\n",
    "      for which to determine the state\n",
    "    + state_gdf : geopandas.GeoDataFrame; a \n",
    "      GeoDataFrame containing state geometries and \n",
    "      their corresponding names\n",
    "    \n",
    "    Outputs\n",
    "    --------------------------------------------------\n",
    "    + Returns the name of the state in which the \n",
    "      polygon is located, or np.nan if no \n",
    "      intersection is found.\n",
    "    '''\n",
    "    state = None\n",
    "    for i in range(len(state_gdf)):\n",
    "        state_geo = state_gdf.loc[i, 'geometry']\n",
    "        if polygon.intersects(state_geo):\n",
    "            state = state_gdf.loc[i, 'shapeName']\n",
    "            return state\n",
    "    if state == None:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc78fde0-d941-416d-a55c-43dce9b38d44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### This gets the state name for each of the \n",
    "### administrative areas\n",
    "india_admin_geos['shapeName'] = india_admin_geos['shapeName'].str.lower().apply(remove_accents)\n",
    "india_admin_geos['stateName'] = india_admin_geos['geometry'].apply(lambda polygon : determine_state(polygon, india_state_geos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ddbdee-72cc-4e4e-9077-30438b4c2259",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### `crop_yields` \\& `cotton_yields`\n",
    "According to the USDA, Maharashtra, Gujarat, Telangana, Rajasthan, & Haryana produce about 80 percent of the cotton in India (which produces about 21 percent of the world's cotton). [source](https://ipad.fas.usda.gov/cropexplorer/cropview/commodityView.aspx?cropid=2631000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdfc3386-5147-4e2f-b13e-7d6927da25da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([ 87,  88,  91,  93,  94,  95,  96,  97,  98,  99, 100, 101, 103, 104,\n",
       "       105, 107, 110, 111, 112, 113, 115, 118, 119, 165, 196, 197, 198, 199,\n",
       "       200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
       "       214, 215, 216, 447, 449, 450, 451, 452, 454, 455, 456, 457, 458, 459,\n",
       "       460, 461, 462, 463, 464, 466, 467, 469, 470, 472, 473, 477, 482, 514,\n",
       "       515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528,\n",
       "       529, 530, 531, 532, 533, 535, 537, 538, 604, 646, 647, 648, 650, 651,\n",
       "       652],\n",
       "      dtype='int64', name='asdf_id')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cotton_states = ['maharashtra', 'gujarat', 'telangana', 'rajasthan', 'haryana']\n",
    "crop_yields['District_Name'] = crop_yields['District_Name'].str.lower().apply(remove_accents)\n",
    "crop_yields['State_Name'] = crop_yields['State_Name'].str.lower().apply(remove_accents)\n",
    "condition = (crop_yields['Crop'] == 'Cotton(lint)') & (crop_yields['State_Name'].isin(cotton_states))\n",
    "cotton_yields = crop_yields[condition].reset_index(drop = True)\n",
    "cotton_yields['Season'] = cotton_yields['Season'].str.strip()\n",
    "\n",
    "### Ensures that values for yr X for both dfs\n",
    "min_yr = max(min(cotton_prices['DATE'].dt.year), min(cd_years))\n",
    "max_yr = min(max(cotton_prices['DATE'].dt.year), max(cd_years))\n",
    "\n",
    "cotton_districts = cotton_yields['District_Name'].unique()\n",
    "cotton_district_ids = india_admin_geos[india_admin_geos['shapeName'].isin(cotton_districts)].index\n",
    "cotton_district_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266f63c4-62fe-4bf9-8d71-b91e8123dc3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### `climate_data` $\\rightarrow$ `cd_rel` (Relevant Climate Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c3408a2-66b5-4116-801d-1b39a62e5aec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### This  will allow climate_data to be joined with india_geos\n",
    "### in the future if need be\n",
    "climate_data['shapeID'] = [i.split(\"-\")[-1] for i in climate_data['shapeID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "84fea2ff-1c18-4d57-9c59-8830b84eed5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d1 = climate_data.filter(like='co2').filter(like='mean').isna().sum().sort_values().reset_index()#.groupby('asdf_id').filter(lambda x: not x.isna().any().any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "dfdcaa03-13d3-4f67-9cd8-2bad9bc75428",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    77\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1[0].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24484f3a-4524-4c90-adf1-4b8696c47335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "desired_cols = ['Shape_Area', 'Shape_Length', 'shapeID', 'shapeName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe3e76d1-fba8-4d59-96f0-c877da255d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = []\n",
    "\n",
    "for col in climate_data.columns:\n",
    "    try:\n",
    "        cat = col.split('.')[-3]\n",
    "        if cat not in categories:\n",
    "            categories.append(cat)\n",
    "    ### For named columns (e.g. 'Shape_Area')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9812fa2a-f0d0-4e3b-8e53-61ac25bc9486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ### If yearly cols wanted uncomment this\n",
    "# desired_categories = {'cru_ts_405_tmp_yearly_mean' : 'yearly_mean_temp', 'cru_ts_405_tmp_monthly_mean' : 'monthly_mean_temp',\n",
    "#                       'cru_ts_405_pre_yearly_mean' : 'yearly_mean_precip', 'cru_ts_405_pre_monthly_mean' : 'monthly_mean_precip',\n",
    "#                       'oco2_v10r_xco2_monthly' : 'co2_concentration', 'ltdr_avhrr_ndvi_v5_monthly' : 'max_ndvi'}\n",
    "\n",
    "### Only contains monthly cols\n",
    "desired_categories = {'cru_ts_405_tmp_monthly_mean' : 'monthly_mean_temp', 'cru_ts_405_pre_monthly_mean' : 'monthly_mean_precip',\n",
    "                      'oco2_v10r_xco2_monthly' : 'co2_concentration', 'ltdr_avhrr_ndvi_v5_monthly' : 'max_ndvi'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8efd9bf-2e7e-4c7d-b6aa-8352a38eb34e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_cols = []\n",
    "\n",
    "### Gets Valid Years\n",
    "for col in climate_data.columns:\n",
    "    try:\n",
    "        yr = col.split('.')[-2]\n",
    "        ### For years like 2000\n",
    "        condition1 = (int(yr) > min_yr - 10) & (int(yr) <= max_yr)\n",
    "        ### For years like 200010 ==> Oct 2000\n",
    "        condition2 = (int(yr) > (min_yr - 10) * 100) & (int(yr) <= max_yr * 100)\n",
    "        if condition1 or condition2:\n",
    "            valid_cols.append(col)\n",
    "    ### For named columns (e.g. 'Shape_Area')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "v2 = []\n",
    "### Gets Valid Categories\n",
    "for col in valid_cols:\n",
    "    cat = col.split('.')[-3]\n",
    "    mode = col.split('.')[-1]\n",
    "    if (cat in desired_categories.keys()) and (mode == 'mean'):\n",
    "        v2.append(col)\n",
    "\n",
    "valid_cols = v2\n",
    "valid_cols.sort()\n",
    "desired_cols.extend(valid_cols)\n",
    "\n",
    "### For memory purposes\n",
    "v2 = None\n",
    "\n",
    "### Prevents valid_cols from being added\n",
    "### multiple times to desired_cols\n",
    "if len(desired_cols) < len(valid_cols):\n",
    "    desired_cols.extend(valid_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9fa1692-c1f5-418e-876d-f6e8b16c65ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### cd_rel ==> Relevant Climate Data\n",
    "cd_rel = climate_data[climate_data.index.isin(cotton_district_ids)][valid_cols]\n",
    "cd_rel = cd_rel.melt(var_name = 'cat', ignore_index = False).reset_index()\n",
    "cd_rel['year'] = cd_rel['cat'].str.split('.').str[-2].str[:-2].astype(int)\n",
    "cd_rel['month'] = cd_rel['cat'].str.split('.').str[-2].str[-2:].astype(int)\n",
    "cd_rel['cat'] = cd_rel['cat'].apply(lambda cat : desired_categories[cat.split('.')[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df8f1be-ee41-46ae-bdeb-709a94190cca",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8151511e-a3f7-469f-9be3-263534e9d7a2",
   "metadata": {},
   "source": [
    "##### `cd_rel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3103323-d5f6-4b5c-869a-bb588ce74be5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_xytd_changes(df, years_back):\n",
    "    '''\n",
    "    Description\n",
    "    --------------------------------------------------\n",
    "    Calculates the percentage change in values over a\n",
    "    specified number of years back for each row in \n",
    "    the DataFrame.\n",
    "    \n",
    "    Inputs\n",
    "    --------------------------------------------------\n",
    "    + df : pandas.DataFrame; the input DataFrame \n",
    "      containing columns 'asdf_id', 'cat', 'year', \n",
    "      'month', and 'value'\n",
    "    + years_back : int; the number of years back to \n",
    "      compare the current value against\n",
    "    \n",
    "    Outputs\n",
    "    --------------------------------------------------\n",
    "    + Returns a list of percentage changes, or NaN if\n",
    "      the comparison value does not exist.\n",
    "    '''\n",
    "    ### Time Complexity : O(n^2)\n",
    "    changes = []\n",
    "    for i in range(len(df)):\n",
    "        row = df.loc[i, :]\n",
    "        asdf_id = row['asdf_id']\n",
    "        cat = row['cat']\n",
    "        curr_yr = row['year']\n",
    "        curr_month = row['month']\n",
    "        curr_val = row['value']\n",
    "        \n",
    "        ### If old_val exists\n",
    "        try:\n",
    "            condition = (df['asdf_id'] == asdf_id) & (df['cat'] == cat) & (df['year'] == curr_yr - years_back) & (df['month'] == curr_month)\n",
    "            old_val = df.loc[condition, 'value']\n",
    "            change = (100 * (curr_val - old_val) / old_val).values[0]\n",
    "            changes.append(change)\n",
    "        except:\n",
    "            changes.append(np.nan)\n",
    "    \n",
    "    return changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09834c8e-4c37-4dfa-b112-c4d6d1094165",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Commented because it takes a long time to run \n",
    "ytd_change1 = get_xytd_changes(cd_rel, years_back = 1)\n",
    "ytd_change3 = get_xytd_changes(cd_rel, years_back = 3)\n",
    "ytd_change5 = get_xytd_changes(cd_rel, years_back = 5)\n",
    "ytd_change10 = get_xytd_changes(cd_rel, years_back = 10)\n",
    "cd_rel['1yr_ytd_change'] = ytd_change1\n",
    "cd_rel['3yr_ytd_change'] = ytd_change3\n",
    "cd_rel['5yr_ytd_change'] = ytd_change5\n",
    "cd_rel['10yr_ytd_change'] = ytd_change10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "fbf5497a-12e1-438d-adff-a3c881826015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ### This is commented out as it is provided in \n",
    "# ### ./data/agricultural_data\n",
    "# path = './data/agricultural_data/cd_rel_raw.csv'\n",
    "# cd_rel.to_csv(path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "e1dcbd34-cd96-4108-8036-258b32fbcbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Uncomment to load in the data\n",
    "path = './data/agricultural_data/cd_rel_raw.csv'\n",
    "cd_rel = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "id": "2a3c2054-287c-4273-93c4-660085c5018d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Too many NaNs values make 'mac_ndvi' and 'co2_concentration' unusable for the current project\n",
    "cd_rel = cd_rel[~(cd_rel['cat'].isin(['max_ndvi', 'co2_concentration']))].reset_index(drop = True)\n",
    "\n",
    "### Only Need entries from Jan 1990 through Dec 2019\n",
    "cd_rel = cd_rel[cd_rel['year'] >= 1990].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "fd30443e-18d0-495a-ac6c-9d23f1115d06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Clean Districts:\n",
      "Up to Ten Years: 86\n",
      "Up to Five Years: 86\n",
      "Up to Three Years: 88\n",
      "Up to One Year: 91\n"
     ]
    }
   ],
   "source": [
    "### Districts with No NaNs for the categories of interest up to 10 yr change\n",
    "cd10yr = cd_rel.groupby('asdf_id').filter(lambda x: not x.isna().any().any())['asdf_id'].unique()\n",
    "\n",
    "### Districts with No NaNs for the categories of interest up to 5 yr change\n",
    "cd5yr = cd_rel.drop(columns = ['10yr_ytd_change']).groupby('asdf_id').filter(lambda x: not x.isna().any().any())['asdf_id'].unique()\n",
    "\n",
    "### Districts with No NaNs for the categories of interest up to 3 yr change\n",
    "cd3yr = cd_rel.drop(columns = ['10yr_ytd_change', \n",
    "                               '5yr_ytd_change']).groupby('asdf_id').filter(lambda x: not x.isna().any().any())['asdf_id'].unique()\n",
    "\n",
    "### Districts with No NaNs for the categories of interest up to 1 yr change\n",
    "cd1yr = cd_rel.drop(columns = ['10yr_ytd_change',\n",
    "                               '5yr_ytd_change',\n",
    "                               '3yr_ytd_change']).groupby('asdf_id').filter(lambda x: not x.isna().any().any())['asdf_id'].unique()\n",
    "print(f'Number of Clean Districts:\\nUp to Ten Years: {len(cd10yr)}\\nUp to Five Years: {len(cd5yr)}\\nUp to Three Years: {len(cd3yr)}\\nUp to One Year: {len(cd1yr)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8d7855-c8ed-4b67-9563-1bc3f4c155da",
   "metadata": {
    "tags": []
   },
   "source": [
    "*Note*: (a) Since there are the same amount of \"clean\" districts at the 5ytd and 10ytd change levels, I use the same df for both. (b) I relplace all the `np.inf` values with **monthly medians**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e7718a-12d1-4b36-b003-447e61252350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_inf(row, val_col, monthly_meds):\n",
    "    '''\n",
    "    Description\n",
    "    --------------------------------------------------\n",
    "    Replaces infinity values in a specified column \n",
    "    of a DataFrame row with corresponding median \n",
    "    values from another DataFrame.\n",
    "    \n",
    "    Inputs\n",
    "    --------------------------------------------------\n",
    "    + row : pandas.Series; a row from the DataFrame \n",
    "      being processed\n",
    "    + val_col : str; the name of the column in which\n",
    "      to check for infinity values\n",
    "    + monthly_meds : pandas.DataFrame; a DataFrame \n",
    "      containing median values indexed by \n",
    "      (year, month, category)\n",
    "    \n",
    "    Outputs\n",
    "    --------------------------------------------------\n",
    "    + Returns the original value if it is not \n",
    "      infinity, otherwise returns the median value \n",
    "      for the corresponding year, month, and category.\n",
    "    '''\n",
    "    val = row[val_col]\n",
    "    if (val == np.inf) or (val == -np.inf):\n",
    "        c = row['cat']\n",
    "        y = row['year']\n",
    "        m = row['month']\n",
    "        new_val = monthly_meds.loc[(y, m, c), val_col]\n",
    "        return new_val\n",
    "    else:\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "id": "19bdaf56-1ae0-4876-b24b-2a1a36c4659e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cd_rel_temp = pd.DataFrame(columns = ['year', 'month', 'cat', 'value'])\n",
    "suffixes = {'value' : 'val', '1yr_ytd_change' : '1ytd', '3yr_ytd_change' : '3ytd',\n",
    "            '5yr_ytd_change' : '5ytd', '10yr_ytd_change' : '10ytd'}\n",
    "\n",
    "### All ytd changes\n",
    "### Makes sure it only runs once\n",
    "if not 'cd_rel_full' in locals():\n",
    "    ### Needed to impute np.inf values\n",
    "    monthly_meds = cd_rel.drop('asdf_id', axis = 1).groupby(['year', 'month', 'cat']).median()\n",
    "\n",
    "    for i in range(len(suffixes)):\n",
    "        s = list(suffixes.keys())[i]\n",
    "        sub_df = cd_rel[cd_rel['asdf_id'].isin(cd5yr)][['asdf_id', 'cat', 'year', 'month', s]]\n",
    "        \n",
    "        ### Replaces np.inf values with monthly medians\n",
    "        sub_df[s] = sub_df.apply(lambda row : replace_inf(row, s, monthly_meds), axis = 1)\n",
    "        \n",
    "        sub_df['cat'] = sub_df.apply(lambda row : f\"{row['cat']}_{row['asdf_id']}_{suffixes[s]}\", axis = 1)\n",
    "        sub_df = sub_df.rename(columns = {s : 'value'})\n",
    "\n",
    "        ### asdf_id col becomes redundant after cat reformatted\n",
    "        sub_df = sub_df.drop(columns = ['asdf_id'])\n",
    "\n",
    "        cd_rel_temp = pd.concat([cd_rel_temp, sub_df])\n",
    "\n",
    "    cd_rel_full = cd_rel_temp.pivot(columns = 'cat', index = ['year', 'month'], values = 'value')\n",
    "\n",
    "    cd_rel_full.columns.name = None\n",
    "\n",
    "    cd_rel_full = cd_rel_full[sorted(cd_rel_full.columns)].reset_index()\n",
    "    \n",
    "    path = './data/agricultural_data/cd_rel_clean_full.csv'\n",
    "    cd_rel_full.to_csv(path, index = False)\n",
    "\n",
    "    ### For memory purposes\n",
    "    cd_rel_temp = None\n",
    "\n",
    "    ### Up to 3ytd\n",
    "    ### Makes sure it only runs once\n",
    "    for i in range(len(suffixes) - 2):\n",
    "        s = list(suffixes.keys())[i]\n",
    "        sub_df = cd_rel[cd_rel['asdf_id'].isin(cd3yr)][['asdf_id', 'cat', 'year', 'month', s]]\n",
    "        \n",
    "        ### Replaces np.inf values with monthly medians\n",
    "        sub_df[s] = sub_df.apply(lambda row : replace_inf(row, s, monthly_meds), axis = 1)\n",
    "        \n",
    "        sub_df['cat'] = sub_df.apply(lambda row : f\"{row['cat']}_{row['asdf_id']}_{suffixes[s]}\", axis = 1)\n",
    "        sub_df = sub_df.rename(columns = {s : 'value'})\n",
    "\n",
    "        ### asdf_id col becomes redundant after cat reformatted\n",
    "        sub_df = sub_df.drop(columns = ['asdf_id'])\n",
    "\n",
    "        cd_rel_temp = pd.concat([cd_rel_temp, sub_df])\n",
    "\n",
    "    cd_rel_3ytd = cd_rel_temp.pivot(columns = 'cat', index = ['year', 'month'], values = 'value')\n",
    "\n",
    "    cd_rel_3ytd.columns.name = None\n",
    "\n",
    "    cd_rel_3ytd = cd_rel_3ytd[sorted(cd_rel_3ytd.columns)].reset_index()\n",
    "    \n",
    "    path = './data/agricultural_data/cd_rel_clean_3ytd.csv'\n",
    "    cd_rel_3ytd.to_csv(path, index = False)\n",
    "\n",
    "    ### For memory purposes\n",
    "    cd_rel_temp = None\n",
    "\n",
    "    ### Up to 1ytd\n",
    "    ### Makes sure it only runs once\n",
    "    for i in range(len(suffixes) - 3):\n",
    "        s = list(suffixes.keys())[i]\n",
    "        sub_df = cd_rel[cd_rel['asdf_id'].isin(cd1yr)][['asdf_id', 'cat', 'year', 'month', s]]\n",
    "        \n",
    "        ### Replaces np.inf values with monthly medians\n",
    "        sub_df[s] = sub_df.apply(lambda row : replace_inf(row, s, monthly_meds), axis = 1)\n",
    "        \n",
    "        sub_df['cat'] = sub_df.apply(lambda row : f\"{row['cat']}_{row['asdf_id']}_{suffixes[s]}\", axis = 1)\n",
    "        sub_df = sub_df.rename(columns = {s : 'value'})\n",
    "\n",
    "        ### asdf_id col becomes redundant after cat reformatted\n",
    "        sub_df = sub_df.drop(columns = ['asdf_id'])\n",
    "\n",
    "        cd_rel_temp = pd.concat([cd_rel_temp, sub_df])\n",
    "\n",
    "    cd_rel_1ytd = cd_rel_temp.pivot(columns = 'cat', index = ['year', 'month'], values = 'value')\n",
    "\n",
    "    cd_rel_1ytd.columns.name = None\n",
    "\n",
    "    cd_rel_1ytd = cd_rel_1ytd[sorted(cd_rel_1ytd.columns)].reset_index()\n",
    "    \n",
    "    path = './data/agricultural_data/cd_rel_clean_1ytd.csv'\n",
    "    cd_rel_1ytd.to_csv(path, index = False)\n",
    "\n",
    "    ### For memory purposes\n",
    "    cd_rel_temp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "id": "ba87a475-3a26-4096-85b2-e2ac395793db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1909cce6-df7d-4b72-b4aa-c9e6be3c718f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
